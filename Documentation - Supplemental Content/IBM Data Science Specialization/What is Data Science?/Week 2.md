# Big Data & Data Mining
Here you use tools such as python, jupyter notebooks, hadoop, pandas (the python library), etc. To manipulate your data.

The Big Data definitions depends on you, there are two important attributes behind it:
- Size: Big Data is done with data in large database systems that are outside of the common data management tools.
- Usage: The techniques, models, patterns used in Big Data are pretty specific of it.

**Hadoop:**

The process:
The data is distributed through lots of servers (computers) running the same program, and this servers have each one a slice of the whole cluster of data. The server runs the program on it's individual part to finally send the results back, those are going to be sorted and redistributed to another process. The first process is the map process, and the second process is the reduce process.

These Big Data servers scale linearly.

Hadoop is an open source clone of the Google Big Data Architecture.

The tools of data sicence have been with us for decades, but the actual capability to create ML algorithms and combine them with our traditional tools (programming, databases, mathematics, statistics, probability, etc.) have open a new sea of possibilities for predicting outcomes, detecting patterns, engineering solutions, build optimization through data, etc.

Deep Learning is pretty new (less than 10 years old) and neural networks are pretty old (30+ years) but untill 2006 there wasn't much you could do with it. And now you have multi-layer neural networks that have massive improvements for what can be done in the field.

**Stablishing data mining goals:** Here you don't just identify the key questions and data to answer those questions. But also the cost and benefits of the excercise. <- The level of the accuracy expected fron the results is a benefit that influences the cost. From certain level of accuracy you don't gain much given the diminishin returns against the cost of the exercise. Everything to see of it is worth it the effort from not just an economical point of view. But also the effectiveness, efficiency and benefits of it.

**Selecting data:** This is critical, because the output depends a lot on the input (which is the data you collect). So you need to know the usability, availability, type, size, and frequency of collection of your data. This is critical for the cost of your data mining process and also the output of your project.

**Preprocessing data:** Selecting your data is the what, preprocessing is the how of your input. On this part you spot irrelevant data that needs to be discarted, identify and deal with errors (i.e. Human errors when parsing on information). Check to ensure the integrity of the data. Develop a formal method to deal with missing data. Is a data cleaning phase.

**Transforming data:**

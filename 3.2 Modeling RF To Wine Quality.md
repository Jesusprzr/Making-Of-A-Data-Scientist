## Introduction
The following modeling process will be concentrated on training and tuning a random forest algorithm for wine quality. Based on traits like acidity, residual sugar, and alcohol concentration. This will be focused on applied machine learning. 

##Why Scickit-Learn?
This is the most premier general-purpose python library for machine learning. Certainly there are others packages that perform better at certain tasks, but the strong point of this one is its versatility and high-level interface for tasks like preprocessing data, cross-validation and stuf that allows us to practice the entire *ML* workflow with good practices and understand the big picture. 

Keep the [Scikit documentation](https://scikit-learn.org/stable/user_guide.html) open on another tab for suplemental reference. 

## 1- Creating our environment
### Create a new jupyter notebook, import libraries and data:

    #Numpy for more efficient numerical computation
    import numpy as np
    #Pandas for more ease on dataframe management
    import pandas as pd

    #Machine learning functions:
    #this module helps choose between models, we're just gonna import one function first
    from sklearn.model_selection import train_test_split
    #the following module for scaling, transforming, and wrangling data
    from sklearn import preprocessing
    #Now the families of models we'll use
    from sklearn.ensemble import RandomForestRegressor 
    #For doing cross-validation
    from sklearn.pipeline import make_pipeline
    from sklearn.model_selection import GridSearchCV
    #Metrics to evaluate model performance later on
    from sklearn.metrics import mean_squared_error, r2_score
    #Finally, a way to persist our model for future use
    from sklearn.externals import joblib
    
Load the dataset **from a remote URL:**

    dURL = 'http://mlr.cs.umass.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'
    ds = pd.read_csv(dURL)
    
    print(ds.head())
      fixed acidity;"volatile acidity";"citric acid";"residual sugar";"chlorides";"free sulfur dioxide";"total sulfur             dioxide";"density";"pH";"sulphates";"alcohol";"quality"
    0   7.4;0.7;0;1.9;0.076;11;34;0.9978;3.51;0.56;9.4;5                                                                                     1   7.8;0.88;0;2.6;0.098;25;67;0.9968;3.2;0.68;9.8;5                                                                                     2  7.8;0.76;0.04;2.3;0.092;15;54;0.997;3.26;0.65;...                                                                                     3  11.2;0.28;0.56;1.9;0.075;17;60;0.998;3.16;0.58...                                                                                     4   7.4;0.7;0;1.9;0.076;11;34;0.9978;3.51;0.56;9.4;5  
    
Looks pretty messy, it seems like the file is actually using semicolons (;) to actually separate the data. That's easilly fixed with:

    ds = pd.read_csv(dataset_url, sep=';')

    print data.head()
    #    fixed acidity  volatile acidity  citric acid...
    # 0            7.4              0.70         0.00...
    # 1            7.8              0.88         0.00...
    # 2            7.8              0.76         0.04... 
    # 3           11.2              0.28         0.56...  
    # 4            7.4              0.70         0.00...
    
Not, to take a look at the data:
  
    print(ds.shape)
    (1599, 12)
    
Okay, now we know that we have 1599 observations and 12 variables/features, incluiding our target feature. Now, for printing summary statistics to get a better feeling of it:

    print(ds.describe())
    #        fixed acidity  volatile acidity  citric acid...
    # count    1599.000000       1599.000000  1599.000000...
    # mean        8.319637          0.527821     0.270976...
    # std         1.741096          0.179060     0.194801...
    # min         4.600000          0.120000     0.000000...
    # 25%         7.100000          0.390000     0.090000...
    # 50%         7.900000          0.520000     0.260000...
    # 75%         9.200000          0.640000     0.420000...
    # max        15.900000          1.580000     1.000000...
    
    Here's the list of all the features:
    quality (target)
    fixed acidity
    volatile acidity
    citric acid
    residual sugar
    chlorides
    free sulfur dioxide
    total sulfur dioxide
    density
    pH
    sulphates
    alcohol

All our features are numeric, but they all have different scales so make a note to remember to standarize later. We are cutting so much of the process of exploratory analysis, but let's move on to the next step because our focus is on *ML*.

## 2 - Split Data Into Train & Test Sets
Doing this at the beggining of the workflow is crucial for the sake of getting realistic stimates of the models performance.
First let's separate out target feature from our input features:

    y = ds.quality
    x = ds.drop('quality', axis = 1)
    
By doing so, it allows us to take advantage of the following function:

    x_train, x_test, y_train, y_test = train_test_split(x, y, 
                                                    test_size=0.2, 
                                                    random_state=123, 
                                                    stratify=y)
                                                    
We've just:
  1.  set aside 20% of the data for testing our model. 
  2.  set an arbitrary random state (seed) so that we can reproduce our results. 
  3.  This **is a really good practice**, and it is to **stratify our sample** by the target variable. This will ensure that our training set looks similar to our test set, making the evaluation metrics more reliable.  
  
## 3 - Declare Data Preprocessing steps
Remember that we said that we needed to standarize our data.
### What Is Standarization?
Is the process of subtracting the means from each feature and then dividing by the feature standard deviation. 

This is a common requirement for *ML* tasks because many algorithms assume that all features are centered around zero and have approximately the same variance.

#### Here is the code we WON'T USE:
It's pretty easy to scale a dataset with *Scikit-Learn*:

    x_train_scaled = preprocessing.scale(x_train)
    print(x_train_scaled)
    # array([[ 0.51358886,  2.19680282, -0.164433  , ...,  1.08415147,
    #         -0.69866131, -0.58608178],
    #        [-1.73698885, -0.31792985, -0.82867679, ...,  1.46964764,
    #          1.2491516 ,  2.97009781],
    #        [-0.35201795,  0.46443143, -0.47100705, ..., -0.13658641,
    # ...
    
We can confirm that the scaled dataset is centered at zero with **unit variance**:

    print(x_train_scaled.mean(axis=0))
    # [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
    print(x_train_scaled.std(axis=0))
    # [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]

So, why we won't use this code?

Because we won't be able to perform exactly the same transformation on our test set. We can scale the test set separatedly but we won't be using the same means and SDs as we used to transforming the trainig set (obviously because the means and SDs will be calculated on that 20% data that was leaved for testing, while the other means and SDs were calculated with the other 80% of the data).

This means that it wouldn't be a fair representation of how the model pipeline, including the preprocessing steps peroform on new data.

#### Here is the code we'll use:
Instead of directly incoking the scale function, we'll use a feature of *Scikit-Learn* called the **Transformer API.** This allows us to fit a preprocessing step using the training data the same way we would fit a model. Then, use the same transformation on future datasets! Here is the process:

  1.  Fit transformer on training set (saving means and SDs)
  2.  Apply transformer on training set (scaling training data)
  3.  Apply transformer to test set (using same means and SDs)
  
This will make our **final stimation of model performance** more realistic. And also will allow us to insert our preprocessing steps into a **cross-validation pipeline.**
